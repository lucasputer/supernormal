% \documentclass[11pt,a4paper,twoside]{tesis}
% SI NO PENSAS IMPRIMIRLO EN FORMATO LIBRO PODES USAR
\documentclass[11pt,a4paper]{tesis}

\usepackage{graphicx}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage[left=3cm,right=3cm,bottom=3.5cm,top=3.5cm]{geometry}
\usepackage{natbib}
\usepackage{mathtools}
\usepackage{ dsfont }
\usepackage{amsthm}
\usepackage[parfill]{parskip}


\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{fact}{Fact}[section]
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]


\usepackage{amsthm}
 

\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
\DeclarePairedDelimiter{\floor}{\lfloor}{\rfloor}


\begin{document}

%%%% CARATULA

\def\autor{Lucas Puterman}
\def\tituloTesis{Números Muy Normales}
\def\runtitulo{Números Muy Normales}
\def\runtitle{Very Normal Numbers}
\def\director{Dra. Verónica Becher}
\def\codirector{Olivier Carton}
\def\lugar{Buenos Aires, 2019}
\input{caratula}

%%%% ABSTRACTS, AGRADECIMIENTOS Y DEDICATORIA
\frontmatter
\pagestyle{empty}
\input{abs_esp.tex}

\cleardoublepage
\input{abs_en.tex} % OPCIONAL: comentar si no se quiere

% \cleardoublepage
% \input{agradecimientos.tex} % OPCIONAL: comentar si no se quiere

\cleardoublepage
\input{dedicatoria.tex}  % OPCIONAL: comentar si no se quiere

\cleardoublepage
\tableofcontents

\mainmatter
\pagestyle{headings}

%%%% ACA VA EL CONTENIDO DE LA TESIS

\chapter{Introduction}


\section{Normality}

Flipping a coin is probably the most basic form of randomness that one can think of. Flip a coin a large number of times and roughly half of them will come up heads and half of them will come up tails.
As sucessive flips are independent, when flipping a coin repeatedly, after observing heads on one given flip, we can equiprobably observe heads or tails in the next one. This means that, if we keep flipping our coin, all combinations of heads and tails have the same chances of happening.

This is the idea captured by Émile Borel  ~\cite{Borel} when he gave the definition of \textit{normality}, a concept that formalizes  the most basic form of randomness for real numbers. Precisely, we say that an infinite sequence of symbols of a given alphabet, for example zeros and ones, is \textit{normal} if all the different blocks of symbols of a given length occur with the same frequency.
Of course that as the sequence is infinite, when we talk about the frequency of occurence of a given block of symbols we are refering to the asymptotic frequency of the block in the sequence.

Let $b$ be an integer greater or equal to 2 that we call a \textit{base}. If we represent a real numebr in a given base, we have the integer part followed by a fractionary expansion, which is a possibly infinite sequence of digits in base $b$.

Fixed a base $b$, the \textit{expansion} of a real number $\alpha$ en base $b$ is a sequence of digits $d_1d_2d_3\dots$ with every $d_i$ between 0 and $b-1$, such that
$$\alpha = \floor{\alpha} + 0,d_1d_2d_3\dots$$

where $\floor{\alpha}$ is the integer part of $\alpha$.

\textbf{Notation}
Let $A$ be a finite set of symbols that we refer as the alphabet. We write $A^k$ to denote the set of words of length $k$ formed with symbols form $A$. The length of a finite word $w$ is denoted by $|w|$.
The positions of finite and infinite words are numbered starting at 1. To denote the symbol at position $i$ of a word $w$, we write $w[i]$, and to denote the substring of $w$ from position $i$ to $j$, we use the notation $w[i \dots j]$.  
Given two words $w$ and $u$, we denote $|w|_u$ as the number of occurrences of $u$ in $w$ and $||w||_u$ as the number of alligned occurrences of $u$ in $w$, or what is to say:
    $$|w|_u = |\{i: w[i \dots i + |u| + 1] = u\}|$$
    $$||w||_u = |\{i: w[i \dots i + |u| + 1] = u \wedge i \equiv 1 \; mod \; |u| \}|$$

For example, $|aaaaa|_{aa} = 4$ and $||aaaaa||_{aa} = 2$.
\\

\begin{definition}
    We say that an ininite sequence $w$ formed of symbols of an alphabet $A$ where $|A| = b$ is \textit{simply normal} when for every $d \in A$ it happens that:
    $$\lim_{N\to\infty} \frac{|w[1 \dots N]|_d}{N} = \frac{1}{b}$$
\end{definition}

\begin{definition}[Normaility]
    We say that an ininite sequence $w$ formed of symbols of an alphabet $A$ where $|A| = b$ is \textit{normal} when for every block $u$ it happens that:
    $$\lim_{N\to\infty} \frac{|w[1 \dots N]|_u}{N} = \frac{1}{b^{|u|}}$$
\end{definition}

\begin{definition}
    We say that a real number is normal in base $b$ if its expansion in base $b$ is a normal sequence. 
    
    Finally, we say that a real number is \textit{absolutely normal} if its expansion is normal for every base.
\end{definition}


\begin{theorem} ~\cite{Borel}
    Almost all real numbers (with respect to Lebesgue measure) are absolutely normal.
\end{theorem}

When Borel proved that almost all real numbers are absolutely normal, he conjectured that irrational algebraic numbers are absolutly normal. However, this problem remains open.
Even though absolutly normal numbers have been found ~\cite{Sierpinski}, the solutions are not fully satisfactory if we take into account that it is not possible to prove any other properties on this numbers other that their absolute normality.
It is still an open problem to prove that any of the mathematical constants such as $\pi$ , $e$ or $\sqrt{2}$ are normal.

However, the problem of giving a number normal to a given base has been solved succesfully. There are several examples but the most famous and simple one of such sequences is the Champernowne sequence ~\cite{champern} written in base 10:
$$0 \; \;2 \;3 \dots 9 \; 10 \; 11 \; 12 \dots 98 \; 99 \; 100 \; 101 \; 102 \dots$$ 
Note that spaces were added for reading convenience.


Champernowne proved this constant to be normal in base 10. The construction can be done in any base, obtaining a numebr normal to that base. It is unknown whether Champernowne numbers are normal to
the bases that are multiplicatively independent to the base used in the construction. There are many interesting generalizations of Champernowne's construction. The following theorem, proved in ~\cite{BC2018} let us give the definition of the Champernowne sequence that is used throughout this thesis.
\\

\begin{theorem}
    Let $A$ be an alphabet. Let $X(n)$ be the concatenation of all words of length $n$ over $A$ in lexicographic order.
     The infinite word $X(1)X(2)\dots$ is normal to alphabet $A$.
\end{theorem}

In the particular case of this work we use a binary alphabet  $A=\{0,1\}$ having $X(n)$ to be the concatenation of all words of length $n$ over the alphabet with two simbols $A=\{0,1\}$ in lexicographic order.Then, for example:
$$X(2) = 00 \: 01 \: 10 \: 11$$

Let the Champernowne sequence be the concatenation of $X(n)$ for $n = 1,2,\dots$ Then the first symbols of the Champernowne sequence are:
$$champ = 0 \: 1 \: 00 \: 01 \: 10 \: 11 \: 000 \: 001 \: 010 \: 011 \: 100 \: 101 \: 110 \: 111 \: 0000 \: 0001 \: \dots$$


\section{Supernormality}

% \begin{definition}
    
%     $$a_k(\lambda) = \frac{e^{-\lambda}\lambda^k}{k!}$$
% \end{definition}

The notion of supernormality was defined by Zeev Rudnick a few years ago. Benjamin Weiss from the Einstein Institute of Math from the Hebrew University gave on June 16th, 2010 a lecture on “Random-like behavior in deterministic systems”  where the notion of \textit{supernormal} sequences is described under the name of \textit{Poisson generic} sequences ~\cite{Weiss}.
 The few things known about this notion are not published. However, in the conference, Weiss claims that almost every real number is supernormal and that the notion of supernormality is stronger than the classical notion of normaility. This means that if a number is supernormal then it is normal, but not the other way around. 
Weiss also states that the most famous example of a normal sequence, the Champernowne sequence, is not supernormal.
Finally, he leaves open the problem of giving an explicit construction of a supernormal number.
In this thesis we will prove that the Chamernowne sequence is not supernormal. This, together with the proof that supernormality implies normality, completes the proof that supernormality is stronger than normality.
Let's start by giving a formal definition of what a supernormal sequence is, which will be explained more in detail later.
\\


\begin{definition}
Let $x$ be a sequence over a binary alphabet.
For $u,w$ words, $|w|_u$ is the number of occurrences of $u$ in $w$.
Let $A^\lambda_{k,n}(x)$ be the frequency of occurrence of words of length $n$ that occur exactly $k$ times in the first $\floor{\lambda(2^n+n-1)}$ symbols of $x$, or what is to say:
$$A^\lambda_{k,n}(x) = \frac{\#\{w: |w| = n  , |x[1...\lfloor\lambda(2^n+n-1)\rfloor]|_w = k\}}{2^n}$$
\end{definition}


\begin{definition}
    Let $\lambda > 0$ be a real number. We say a binary sequence $x$ is $\lambda-$supernormal if $\forall k \in \mathds{N}_{0}$ $$\lim_{n\to\infty} A^\lambda_{k,n}(x) = \frac{e^{-\lambda}\lambda^k}{k!}$$ for each integer $k \geq 0$.
\end{definition}

\begin{definition}[Supernormality]
    We say a binary sequence $x$ is supernormal if it is $\lambda-$supernormal $\forall \lambda > 0$
\end{definition}


% The idea behind normality is to look at increasing finite sample spaces of the sequence and check that for each block $b$, the frequency of appearance of converges to $\frac{1}{2^{|b|}}$.
% In the case of supernormality, the difference relies in the fact that what are some calculated i

The idea behind normality is to look at increasing finite sample spaces of the sequence and check that for each block, the frequency of appearance is the same as the one for each of all the possible blocks.
Supernormality doesn't look at at the frequence of occurence a block as normality does. We could say that $A^\lambda_{k,n}(x)$ is conducting some simple statistics where for each block of length $n$ we are counting how many times it occurs. 
 Then, the probability that a block occurs $k$ times is the number of blocks that occur $k$ times in the first $\floor{\lambda(2^n + n - 1)}$ symbols of the sequence divided by all the possible blocks.
For a sequence to be supernormal, we need these proportions to converge in distribution to a Poisson distribution with parameter $\lambda$.
It is important to notice that the $\lambda$ parameter is setting up how much of the sequence we will read in order to conduct the statistics, and that it may not be an integer, we need to take the integer part in order to consume an integer number of symbols of the sequence.


Let's take as an illustrative example the finite sequence $x = 1001111001$. Taking $n=3$ and $\lambda = 1$, the words of length $n$ that occurr in $x$ are:
$$100 \; 001 \; 011\; 111\; 111\; 110\; 001$$

Now if we count the occurrences of every possible word of length $3$ we have:

\begin{center}
    \begin{tabular}{|c | c|} 
    \hline
    Word & Count \\ [0.5ex] 
    \hline
    000 & 0 \\ 
    \hline
    001 & 2 \\ 
    \hline
    010 & 0 \\ 
    \hline
    011 & 1 \\ 
    \hline
    100 & 1 \\ 
    \hline
    101 & 0 \\ 
    \hline
    110 & 1 \\ 
    \hline
    111 & 2 \\ 
    \hline
   \end{tabular}
\end{center}

And now we can see the frequence and the count of every possible $k$ with their expected value if the sequence were supernormal which is $\frac{e^{-\lambda}\lambda^k}{k!}$ :

\begin{center}
    \begin{tabular}{|c | c |  c| c |} 
    \hline
    $k$ & Count &  Frequency & Expected Frequency \\ [0.1ex] 
    \hline
    0 & 3 & $\frac{3}{8}$ & $e^{-1} $ \\ [0.5ex] 
    \hline
    1 & 3 &$\frac{3}{8}$ & $e^{-1} $ \\  [0.5ex] 
    \hline
    2 & 2 &$\frac{1}{4}$ & $\frac{e^{-1}}{2} $ \\  [0.5ex] 
    \hline
    3 & 0 & 0 & $\frac{e^{-1}}{3!} $ \\  [0.5ex] 
    \hline
    4 & 0 & 0 & $\frac{e^{-1}}{4!} $ \\ [0.5ex] 
    \hline
    5 & 0 & 0 & $\frac{e^{-1}}{5!} $ \\ [0.5ex] 
    \hline
    6 & 0 & 0  & $\frac{e^{-1}}{6!} $ \\ [0.5ex] 
    \hline
    7 & 0 & 0 & $\frac{e^{-1}}{7!} $ \\ [0.5ex] 
    \hline
    8 & 0 & 0 & $\frac{e^{-1}}{8!} $ \\  [0.5ex] 
    \hline
   \end{tabular}
\end{center}

Of course this is just a finite simple example, but for an infinite sequence to be supernomal, we need these frequencies to converge to a Poisson point process when $n \rightarrow \infty$. 

As a more complex example we can analize what happens in the Champernowne sequence, which can also help us build an intuition on how to approach a proof for its non-normality.
The following figures show for every $k$ taking $\lambda = 1$ and $n = 22$, the observed frequencies next to the expected ones.

% \begin{figure}[h]
%     \includegraphics[width=10cm]{images/champ-16-freq.png}
%     \centering
%     \caption{Observed and expected frequencies for $n = 16$ and $\lambda = 1$}
%     \label{fig:champ-16-freq}
% \end{figure}

\begin{figure}[h]
    \includegraphics[width=10cm]{images/champ-22-freq.png}
    \centering
    \caption{Observed and expected frequencies for $n = 22$ and $\lambda = 1$}
    \label{fig:champ-22-freq}

\end{figure}

As it can be observed in Figure\ref{fig:champ-22-freq}, the amount of words of length $n$ that do not appear in the first $2^n + n - 1$ symbols of Champernowne is much higher than the expected one for the sequence to be 1-supernormal. As we will observe later in the proof this is due to the fact that by the way that Champernowne is constructed.
This experiment as well a supernormality check for other famous normal sequences and a few PRNSs are available at ~\cite{Puterman}

% One more interesting thing to do experimentaly is to check wether some pseudorandom number generators generate sequences that empiricaly appear to be supernormal. We analized what happened with sequences genereated with the Mersenne Twister PRNG which is the PRNG used by Python and with the cellular autmata Rule 30 which was used as the PRNG in Mathematica.

%% ...
\chapter{Supernormality is stronger than normality}
\section{Supernormality implies normality (Proof by Olivier Carton)}



\begin{fact}
    $$\sum_{k \geq 0} a_k(\lambda) = e^{-\lambda}\sum_{k \geq 0} \frac{\lambda^k}{k!} = e^{-\lambda}e^{\lambda} = 1$$
\end{fact}

\begin{fact}
    $$\sum_{k \geq 0} ka_k(\lambda) = e^{-\lambda}\sum_{k \geq 1} \frac{\lambda^k}{(k-1)!} = \lambda e^{-\lambda} \sum_{k \geq 0} \frac{\lambda^k}{k!}= \lambda$$
\end{fact}





\begin{fact}
    $$\sum_{k \geq 0} A_{k,n} = 1$$
\end{fact}

\begin{fact}
    $$A_{k,n} = 0 \textrm{ if } k > \lambda2^n$$
\end{fact}

Let $\epsilon > 0$ be chosen.

Let $k_0$ be chosen such that 
$$\frac{1}{\lambda} \sum_{k > k_0} ka_k(\lambda) < \frac{\epsilon}{2}$$

Let $n_0$ be chosen such that 
$$\forall i,n \: s.t \:  0 \leq i \leq k_0 - 1 \wedge n > n_0 \wedge |A_{i,n}(\lambda) - a_i(\lambda)| \leq \frac{\epsilon\lambda}{2k_0(k_0+1)}$$

$$Rq? = \sum_{i=0}^{k_0-1} ka_k(\lambda) = \lambda - \sum_{k\geq k_0} ka_k(\lambda) \geq (\lambda - \frac{\epsilon}{2})$$

Consider the positions from 1 to $\lfloor\lambda2^n\rfloor$ in $x$. A position is ``blamed'' if the word of length $n$ starting at that position occurs more than $k_0$ times in $x\lfloor\lambda(2^n+n-1)\rfloor$.

The number of non-blamed positions is


\begin{align*}
    \sum_{i=0}^{k-1} iA_{i,n}(\lambda) 2^n &\geq 2^n\sum_{i=0}^{k-1} i (a_i(\lambda) - \frac{\epsilon\lambda}{2k_0(k_0+1)}) \\
    &\geq 2^n \sum_{i=0}^{k-1} ia_{i}(\lambda) - \frac{2^n\epsilon\lambda}{2} \\
    &\geq 2^n\lambda (1-\frac{\epsilon}{2}) - \frac{2^n\epsilon\lambda}{2} \\
    &= 2^n\lambda(1-\epsilon) \\
\end{align*}

We cover the positions of $1\dots \lambda2^n$ by blocks of length such that blocks do not start at a blamed  position. However a block may contain blamed positions.
 
$$\overbracket{\raisebox{6.4pt}{\qquad}}^{n} \overbracket{\raisebox{6.4pt}{\qquad}}^{n}\times\times\overbracket{\;\quad \times}^{n} \times \overbracket{\raisebox{6.4pt}{\qquad}}^{n} \overbracket{\raisebox{6.4pt}{\qquad}}^{n} \times \overbracket{\;\; \times \times}^{n} \times\times\times \overbracket{\raisebox{6.4pt}{\qquad}}^{n}$$


The number of left positions is less than $\epsilon\lambda2^n$. For a fixed word $w$, the number of bad blocks is $o($number of possible blocks$)$. Since each block can occur at most  $k_0 - 1$ times then it is ok.
Hot spot lemma  is needed to conclude.


\section{Normality does not imply supernormality}
We aim to prove that normality does not imply supernormality. For this we prove that the Champernowne sequence, proven to be normal in ~\cite{BC2018}, fails to be supernormal by proving that it is not 1-supernormal.
The strategy followed to achieve this is similar to the ones used in ~\cite{BCC2019} and  ~\cite{PS2019}.


Let $X(n)$ be the concatenation of all words of length $n$ over the alphabet with two simbols $\mathcal{A}=\{0,1\}$ in lexicographic order.  It is clear that $X(n)$ has length $n2^n$. Then, for example:
$$X(2) = 00 \: 01 \: 10 \: 11$$
Note that spaces were added for reading convenience.

Let the Champernowne sequence be the concatenation of $X(n)$ for $n = 1,2,\dots$ Then the first symbols of the Champernowne sequence are:
$$champ = 0 \: 1 \: 00 \: 01 \: 10 \: 11 \: 000 \: 001 \: 010 \: 011 \: 100 \: 101 \: 110 \: 111 \: 0000 \: 0001 \: \dots$$

By the definition of $\lambda$-supernormality, if we take $\lambda = 1$, then we need to prove that

$$\lim_{n\to\infty} A_{k,n}(1) = a_k(1)$$
$$\lim_{n\to\infty} \frac{\#\{w: |w| = n  , |x[1...(2^n+n-1)]|_w = k\}}{2^n} \neq \frac{e^{-1}}{k!}$$

\bigskip

First, let's see that given $d$, we define $k = 2^d$, if we take $n \geq d + k + 1$ then the whole block $X(k)$ covered in the first $2^n$ symbols of Champernowne.


\begin{fact}
    $\forall n, n  \geq 2$ it follows that $\sum_{i=1}^n i2^i < 2^{n + log(n) + 1}$ 
\end{fact}

\begin{fact} \label{p2}
    $X(k)$ accounts for half of the total amount of symbols in the first $2^{d+k+1}$ symbols of Chamernowne.
\end{fact}
\begin{proof}
    $2^{d+k+1} = 2^{d+k}2$ and $X(k)$ has length $k2^k = 2^d2^k = 2^{d+k}$ 
\end{proof}

We prove that Champernowne is not supernormal by showing that the frequence of words of length $k+d+1$ that do not occur in the first $2^{k+d+1}$ symbols of the Champernowne sequence is higher that the expected frequency if it were supernormal.
To accomplish this, we exhaustively look how many different words of length $2^{k+d+1}$ are there within $X(k)$ and give an upper bound for the amount of different words that can appear in the first $2^{k+d+1}$ symbols of the Champernowne sequence.

Now, let's take a look at what the words of length $k + d + 1$ that occur in $X(k)$ look like. There are four different cases that can happen of how a word $x$ is formed with elements from $X(k)$. 
In the following analysis, $u, v$ and $w$ are consecutive words of length $k$ in $X(k)$:

\begin{itemize}
  \item \underline{Case 1:} 
  $$x = u_1 u_2 \dots u_k \quad v_1 v_2 \dots v_{d} v_{d + 1}$$
    Which means it is the occurrence modulo 0 for a given word $u$ of length $k$ in $X(k)$ plus the remaining $d + 1$ symbols which are taken from the next word.

  \item \underline{Case 2:} 
  $$ x = u_{k-d-1} \dots u_k \quad v_1 v_2 \dots v_k$$
  Which is the case where the word of length $k + d + 1$ is formed from the last $d + 1$ symbols of a word and the whole $k$ symbols of the next word.

  \item \underline{Case 3:} 
  $$x = u_{n+1} u_{n+2} \dots u_k \quad  v_1 v_2 \dots v_{d+n+1} $$
with $n \in \{1,2,\dots ,k - d - 2\}$.

   Which is the case where the $k + d + 1$ symbols are taken from two words of length $k$ and none of the words is complete.

  
  \item \underline{Case 4:} 
  $$ x = u_{k-d-1+n} u_{k-d+n} \dots u_k \quad v_1 v_2 \dots v_k \quad w_1 w_2 \dots w_{d+1-n}$$
  with $n \in \{1, 2, \dots , d\}$
  Which is the case where the word of length $k + d + 1$ is formed by a full word, and the extra $d + 1$ symbols are taken from both the end of the previous word and the beggining of the next one.

  \item \underline{Case 5:} 
  
   In the previous cases we considered every word $u$ such that there is a word $v$ and in case 4 two words $v$ and $w$ that come after $u$ in $X(k)$. This is not true for the las two words of $X(k)$ so we consider them a different case.
  

\end{itemize}



\subsection{Case Analysis}
For the simplicity of the proof we define the function $next(w)$ that is used repetidely in the case analysis.

\begin{definition}
    Let $next(w):\mathcal{A}^n \rightarrow \mathcal{A}^n $ be $|w|$ times 0 if $w$ only consists of $1s$ and the word that comes after $w$ in lexicographic order in any other case.
\end{definition}

\subsubsection{Case 1}
$$x = u_1 u_2 \dots u_k \quad v_1 v_2 \dots v_{d} v_{d + 1}$$

This case accounts for the occurrence modulo 0 for a given word u of length $k$ in $X(k)$ plus the remaining $d + 1$ symbols which are taken from the next word.
As an example, some of the words of length $k + d + 1$ formed from $X(k)$ taking $k = 8, d = 3$ are shown between brackets:

$$( 00000000 \qquad 0000 ) \; 0001$$
$$( 00000001 \qquad 0000 ) \; 0010$$
$$( 00000010 \qquad 0000 ) \; 0011$$
$$\vdots$$
$$( 00001110 \qquad 0000 ) \; 1111$$
$$( 00001111 \qquad 0001 ) \; 0000$$
$$( 00010000 \qquad 0001 ) \; 0001$$
$$\vdots$$
$$( 11111110 \qquad 1111 ) \; 1111$$

There are two important things to notice here. The first one is that as the words of length $k + d + 1$ are formed by a full word of length $k$ followed by the first $d + 1$ symbols from the next word, in almost every case the first $d + 1$ symbols are equal to the last $d + 1$.
The only way for this not to happen, is when the last $k - d - 1$ symbols from the first word $u$ are all $1s$, which means that the next word in lexicographic order $v$ consists of $next(v_1 v_2 \dots v_{d + 1})$ concatenated with $next(v_{d + 2} v_{d + 3} \dots v_{k})$.

The second important thing to notice is that as $X(k)$ is the concatenation of all words of length $k$, all words of length $k$ occur one time in an alligned position modulo $k$. This means that the first $k$ symbols of $x$ takes every possible configuration. 

These two facts leave two possible schemes for what a word $x$ of case 1 may look like:

$$\underbrace{\quad A \quad }_{d +1} \qquad \underbrace{\quad B \quad }_{k - d - 1}  \qquad A$$


$$\underbrace{\quad A \quad }_{d +1} \qquad \underbrace{ 11 \dots 1  }_{k - d - 1}  \qquad next(A) $$

For the first scheme we have:
$$2^{d + 1}  (2^{k - d - 1} - 1)$$
$$ 2\cdot2^{d}  (\frac{2^k}{2\cdot2^d} - 1)$$
$$ 2^k - \frac{1}{2\cdot2^{d} }$$

$ 2^k - \frac{1}{2\cdot2^{d} }$ different words.

For the second scheme we substract one to the cases due to the fact that the last word of length $k$ in $X(k)$ has its continuation outside $X(k)$:
$$2^{d + 1}   - 1$$
$$2\cdot 2^d - 1$$
$ 2\cdot 2^d - 1 $ different words.
\\

Counting the whole case together we have $  2^k - \frac{1}{2\cdot2^{d} } + 2\cdot 2^d - 1$ which is less than $2^k -  2\cdot 2^d$ different words.

\subsubsection{Case 2}
$$ x = u_{k-d-1} \dots u_k \quad v_1 v_2 \dots v_k$$

This case accounts for the occurrence modulo 0 for a given word u of length $k$ in $X(k)$ plus the remaining $d + 1$ symbols which are taken from the previous word. This means that in this case the word of length $k + d + 1$ corresponding to the first word of $X(k)$ does not have a corresponding word inside $X(k)$.
As an example, some of the words of length $k + d + 1$ formed from $X(k)$ taking $k = 8, d = 3$ are shown between brackets:

$$0000 \; (0000 \qquad 00000001)$$
$$0000 \; ( \; 0001 \qquad 00000010)$$
$$\vdots$$
$$0000 \; (1111 \qquad 10000000)$$
$$1000 \; (0000 \qquad 10000001)$$
$$\vdots$$
$$1111 \; (1110 \qquad 11111111)$$

As in the previous case, as $X(k)$ is the concatenation of all words of length $k$, all words of length $k$ occur one time in an alligned position modulo $k$. This means that the last $k$ symbols of $x$ take every possible configuration.
The other important thing to notice is that as the first $d + 1$ symbols of $x$ come from the word $u$ which occups exactly before $v$ in lexicographic order, then: 
$$next(u_{k-d-1} u_{k-d} \dots u_k) = u_{v-d-1} v_{k-d} \dots v_k$$

This leaves only one possible scheme for what a word $x$ of case 2 may look like:

$$\underbrace{\quad A \quad }_{d +1} \qquad \underbrace{\quad B \quad }_{k - d - 1}  \qquad next(A)$$

This scheme gives us the following amount of different words that may occur:
$$(2^{d + 1} 2^{k-d})-1$$
$$ 2\cdot 2^d  (\frac{2^k}{2^d}) - 1$$
$$ 2 \cdot 2^k - 1$$

$ 2 \cdot 2^k - 1 $ different words which is less than $2 \cdot 2^k$ diffrent words.

\subsubsection{Case 3}
$$x = u_{n+1} u_{n+2} \dots u_k \quad  v_1 v_2 \dots v_{d+n+1} $$
with $n \in \{1,2,\dots ,k - d - 2\}$.
\\

This case accounts for when the $k + d + 1$ symbols are taken from two words of length $k$ and none of the words is complete.
As an example, some of the words of length $k + d + 1$ formed from $X(k)$ taking $k = 8, d = 3$ are shown between brackets
Some extra spaces are added within $u$ and $v$ to make clear the scheme explained later.
Taking $n = 1$.


$$0\; (0000\; 000 \qquad 0 \;0000 ) \;001$$
$$0\; (0000 \;001 \qquad 0 \;0000 ) \;010$$
$$\vdots$$
$$0\; (0001 \;110 \qquad 0 \;0001 ) \;111$$
$$0\; (0001 \;111 \qquad 0 \;0010 ) \;000$$
$$0\; (0010 \;000 \qquad 0 \;0010 ) \;001$$
$$\vdots$$
$$1\; (1111 \;101 \qquad 1 \;1111 ) \;110$$
$$0\; (1111 \;110 \qquad 1 \;1111 ) \;111$$

Taking $n = k - d - 2 = 3$

$$000\; (0000\; 0 \qquad 000 \;0000 ) \;1$$
$$000\; (0000\; 1 \qquad 000 \;0001 ) \;0$$
$$000\; (0001\; 0 \qquad 000 \;0001 ) \;1$$
$$000\; (0001\; 1 \qquad 000 \;0010 ) \;0$$
$$\vdots$$
$$111\; (1110\; 1 \qquad 111 \;1111 ) \;0$$
$$111\; (1111\; 0 \qquad 111 \;1111 ) \;1$$

In this case, it also happens that as $X(k)$ is the concatenation of all words of length $k$, for each value of $n$, all words of length $k$ take the $u$ position once, except the last of the words of length $k$ in $X(k)$.

It is important to notice that for a given value of $n$, the first $n$ symbols of $u$ are not be considered to form $x$. This means that it can be interepreted that the symbols from  $u$ that are considered are, the first $d + 1$ symbols after $n$ which are called $A$ and the remaining $k - d - 1 - n$ symbols which are be called $B$.

Now, if we divide the $n + d + 1$ symbols that are used from $v$ to form $x$ into the first $n$ symbols which are called $C$ and the remaining $d + 1$ symbols, it is possible to see that these $d + 1$ symbols are always equal to the symbols from $A$ except for the case where $B$ = $11\dots1$ as they account for the same indexes of $u$ and $v$ and $v$ comes immediately after $u$ in lexicographic order. 


These leave two possible schemes for what a word x of case 3 may look like:

$$\underbrace{\quad A \quad }_{d +1} \qquad \underbrace{\quad B \quad }_{k - d - 1 - n}  \qquad \underbrace{\quad C \quad }_{n} \qquad A$$

$$\underbrace{\quad A \quad }_{d +1} \qquad \underbrace{\; 11\dots1 \; }_{k - d - 1 - n}  \qquad \underbrace{\quad C \quad }_{n} \qquad next(A)$$

Looking closely at the first scheme, it is possible to see, if we put together $B$ and $C$ which have length $k - d - 1 - n$ and $n$ respectively, that we have the following scheme:

$$\underbrace{\quad A \quad }_{d +1} \qquad \underbrace{\quad B \quad }_{k - d - 1}  \qquad A$$

which is exactly the same one as in case 1. This means that all the possible words that can be formed following this scheme don't yield any new words.
\\
The same thing happens with the second scheme when concatenating $11\dots1$ with $C$:

$$\underbrace{\quad A \quad }_{d +1} \qquad \underbrace{\; 11\dots1C \; }_{k - d - 1}  \qquad next(A)$$

Which is a particular case of case 2.

This means that for case 3 there are no words that appear that should be taken into account as new words.


\subsubsection{Case 4}
$$ x = u_{k-d-1+n} u_{k-d+n} \dots u_k \quad v_1 v_2 \dots v_k \quad w_1 w_2 \dots w_{d+1-n}$$
with $n \in \{1, 2, \dots , d\}$

This case accounts for when the $k + d + 1$ symbols are taken from three words of length $k$. The $k$ symbols of $v$ are used and the remaining $d + 1$ symbols are taken from both the previous and the following words $u$ and $w$.
As an example, some of the words of length $k + d + 1$ formed from $X(k)$ taking $k = 8, d = 3$ are shown between brackets
Some extra spaces are added within $u$ and $v$ to make clear the scheme that is explained later.

Taking $n = 1$.
$$0000000\; (0 \qquad 000 \; 0000 \; 1 \qquad 000) \: 00010$$
$$0000000\; (1 \qquad 000 \; 0001 \; 0 \qquad 000) \: 00011$$
$$\vdots$$
$$0011111\; (0 \qquad 001 \; 1111 \; 1 \qquad 001) \: 10000$$
$$0011111\; (1 \qquad 010 \; 0000 \; 0 \qquad 010) \: 00001$$
$$\vdots$$
$$1111110\; (1 \qquad 111 \; 1111 \; 0 \qquad 111) \: 11111$$

Taking $n = 2$.
$$000000\; (00 \qquad 00 \; 0000 \; 01 \qquad 00) \: 000010$$
$$000000\; (01 \qquad 00 \; 0000 \; 10 \qquad 00) \: 000011$$
$$\vdots$$
$$001111\; (01 \qquad 00 \; 1111 \; 10 \qquad 00) \: 111111$$
$$001111\; (10 \qquad 00 \; 1111 \; 11 \qquad 01) \: 000000$$
$$001111\; (11 \qquad 01 \; 0000 \; 00 \qquad 01) \: 000001$$
$$\vdots$$
$$111111\; (01 \qquad 11 \; 1111 \; 10 \qquad 11) \: 111111$$

In this case, it also happens that as $X(k)$ is the concatenation of all words of length $k$, for each value of $n$, 
all words of length $k$ take the $u$ position once, except the last of the words of length $k$ in $X(k)$.

We call $A$ the first $n$ symbols of $x$ which are taken from the end of $v$. The following $d + 1 - n$ symbols which are the first of $v$ are called $B$ and it happens that unless the remaining symbols of $v$ are all $1s$, 
they are be the same as the last $d + 1 - n$ of $x$ because these symbols are the first $d + 1 - n$ from $w$.
Now, we consider the remaining $k - d - 1 + n$ symbols from $v$ as two blocks, one block $C$ of length $k - d - 1$ and the remaining $n$ symbols which are exctly $next(A)$ as $v$ is the next word in lexicographic order after $u$.
This yields the two following schemes:

$$\underbrace{\quad A \quad }_{n} \qquad \underbrace{\quad B \quad }_{d + 1 - n}  \qquad \underbrace{\quad C \quad }_{k-d+1} \qquad next(A) \qquad B$$

$$\underbrace{\quad 11\dots10 \quad }_{n} \qquad \underbrace{\quad B \quad }_{d + 1 - n}  \qquad \underbrace{\; 11\dots1 \; }_{k-d+1} \qquad next(A) \qquad next(B)$$

For the first scheme we have:

$$\sum_{n=1}^{d}(2^n - 1) (2^{d + 1 - n}) (2^{k - d - 1})$$
$$\sum_{n=1}^{d}(2^n - 1) (\frac{2 \cdot 2^d}{2^n})     (\frac{2^k}{2 \cdot 2^d})$$
$$ 2^k \sum_{n=1}^{d} \frac{2^n - 1}{2^n} $$

% Here we would need to substract the cases for when $v$ is the last word of $X(k)$, however as we are giving an upper bound for the words that appear in Champernowne, the result still holds taking this number.

For the second scheme we have:

$$ \sum_{n=1}^{d} 2^{d + 1 - n}$$
$$ \sum_{n=1}^{d} 2 \frac{2^d}{2^{- n}}$$
$$ 2 \cdot 2^d \sum_{n=1}^{d} 2^{- n}$$

When putting them both together we get:

$$  2^k \sum_{n=1}^{d} \frac{2^n - 1}{2^n}  + 2 \cdot 2^d \sum_{n=1}^{d} 2^{- n} < d2^k + 2 \cdot 2^d$$

\subsubsection{Case 5}

We consider the last to words of $X(k)$ as special cases. The last word of $X(k)$ does not apply to any of the cases since there are no words $v$ and $w$ inside $X(k)$ to consider the cases. Something similar occurs with the word previous to the last one and case 4. 
While it is true that we do know which words come immediately after  $X(k)$, which are the first words of size $d+k+2$ in lexicographic order, as we are giving an upper bound, it is valid to consider all of these as different words to all of the ones considered in the previous cases.
By doing this, we would have to consider $d+k+1$ new words for the last word and $d$ words for the previous one. So this yields $2d+k+1$ words to consider.


\subsection{Bounding words that appear in Champernowne}

If the Champernowne sequence were supernormal then the expected frequency of words that appear at least one time in the first $2^n + n -1$ symbols would be:
$$\lim_{n\to\infty} \frac{\#\{w: |w| = n  , |champ[1...(2^n+n-1)]|_w > 0\}}{2^n}  = 1 - e^{-1}$$


Now, by Fact \ref{p2} we know that $X(k)$ accounts for half of the words of the first $2^{d+k+1}$ symbols of Champernowne. 
If we analize what happens with words of length $d+k+1$ using the bounds we have for the occurrences of different words within $X(k)$ and we assume that the remaining $2^{d+k} + d + k - 1$  symbols are all different, then



$$\lim_{d\to\infty} \frac{\#\{w : |w| = d+k+1, |champ[1 \dots 2^{d+k+1}+d+k+1-1]|_w > 0 \}}{2^{d+k+1}} =$$
$$\lim_{d\to\infty} \frac{\#\{w : |w| = d+k+1, |champ[1 \dots 2^{d+k+1}+d+k]|_w > 0 \}}{2^{d+k+1}} <$$
$$\lim_{d\to\infty} \frac{ \textrm{Case 1} + \textrm{Case 2}+ \textrm{Case 4} + \textrm{Case 5} + \textrm{other half} + (d + k) }{2^{d+k+1}} =$$
$$\lim_{d\to\infty} \frac{(2^k - 2\cdot 2^d) + (2 \cdot 2^k)+ (d2^k + 2 \cdot 2^d) + (2d+k+1) + (2^{d+k}) + (d + k) }{2^{d+k+1}} =$$
$$\lim_{d\to\infty} \frac{(2^k - 2k) + (2 \cdot 2^k)+ (d2^k + 2k) + (3d+2k+1) + (k2^{k})}{2k2^{k}} =$$
$$\lim_{d\to\infty} \frac{3\cdot2^k + d2^k  + 3d+2k+1}{2k2^{k}} + \frac{1}{2} =$$
$$\lim_{d\to\infty} \frac{3}{2k} + \frac{d}{2k} + \frac{d}{k2^{k}} + \frac{1}{2\cdot2^{k}} + \frac{1}{2k2^{k}} + \frac{1}{2} = \frac{1}{2} < 1 - e^{-1}$$


Finally, if in the original sequence we consider that the $n$'s such that $n = d + 2^d + 1$ are a subsequence of $n=1,2,\dots$ then we can say that if
$$\lim_{n\to\infty} \frac{\#\{w: |w| = n  , |champ[1...(2^n+n-1)]|_w > 0\}}{2^n}$$
exists, then it is not $1 - e^{-1}$.
This implies that Champernowne is not 1-supernormal which means it is not supernormal.

\begin{corollary}
If $x$ is a normal number it is not implied that $x$ is supernormal.
\end{corollary}


% \chapter{Conclusions and Further Work}

%%%% BIBLIOGRAFIA
\chapter{Bibliography}
\backmatter
\bibliographystyle{alpha}
\bibliography{tesis}



\end{document}
